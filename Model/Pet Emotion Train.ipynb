{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f67208c-541c-4588-9431-305865a38198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.15.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\yujus\\anaconda3\\envs\\dl\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: tensorflow-decision-forests, tensorflow-serving-api, tensorflowjs\n"
     ]
    }
   ],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e576599a-0e55-4c5a-a37d-163418b23f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import time\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e118da84-e8ee-4c35-846f-204918289c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 4 classes.\n",
      "Found 36 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_path = 'data/Master Folder/train'\n",
    "validation_path = 'data/Master Folder/valid'\n",
    "\n",
    "img_width = 224\n",
    "img_height = 224\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    #rescale = 1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.4,0.6],\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    ")\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'rgb',\n",
    "    shuffle = True,\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    validation_path,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size = batch_size,\n",
    "    class_mode = 'categorical',\n",
    "    color_mode = 'rgb',\n",
    "    shuffle = True,\n",
    "    seed = 42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bbfb775-4887-46a0-80c6-9abb68aadb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 112, 112, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 112, 112, 64)     256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 112, 112, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 56, 56, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 56, 56, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 56, 56, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 28, 28, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 28, 28, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 50176)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               25690624  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,769,092\n",
      "Trainable params: 25,768,708\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " efficientnetb5 (Functional)  (None, 2048)             28513527  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 2048)             8192      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               524544    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,079,675\n",
      "Trainable params: 562,052\n",
      "Non-trainable params: 28,517,623\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.layers.Input(shape=(224,224,3))\n",
    "conv1 = tf.keras.layers.Conv2D(kernel_size=(3,3), padding=\"same\", activation=\"relu\", filters=64, input_shape=(224,224,3))(input)\n",
    "#test dropout layers after activation layers\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "bn1 = tf.keras.layers.BatchNormalization()(pool1)\n",
    "\n",
    "conv2 = tf.keras.layers.Conv2D(kernel_size=(3,3), padding=\"same\", activation=\"relu\", filters=64)(bn1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "bn2 = tf.keras.layers.BatchNormalization()(pool2)\n",
    "\n",
    "conv3 = tf.keras.layers.Conv2D(kernel_size=(3,3), padding=\"same\", activation=\"relu\", filters=64)(bn2)\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "bn3 = tf.keras.layers.BatchNormalization()(pool3)\n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(bn3)\n",
    "\n",
    "#test dropout layers between dense layers\n",
    "Dense1 = tf.keras.layers.Dense(512, activation='relu')(flatten)\n",
    "Drop1 = tf.keras.layers.Dropout(.2)(Dense1)\n",
    "#Dense2 = tf.keras.layers.Dense(512, activation='relu')(Drop1)\n",
    "#Drop2 = tf.keras.layers.Dropout(.2)(Dense2)\n",
    "#Dense3 = tf.keras.layers.Dense(256, activation='relu')(Drop2)\n",
    "#Drop3 = tf.keras.layers.Dropout(.2)(Dense3)\n",
    "#Dense4 = tf.keras.layers.Dense(256, activation='relu')(Drop3)\n",
    "#Drop4 = tf.keras.layers.Dropout(.2)(Dense4)\n",
    "Output = tf.keras.layers.Dense(4, activation='softmax')(Drop1)\n",
    "\n",
    "base_model = tf.keras.applications.efficientnet.EfficientNetB5(include_top= False, weights= \"imagenet\", input_shape= (224,224,3), pooling= 'max')\n",
    "base_model.trainable = False\n",
    "transfer_model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    tf.keras.layers.BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128,kernel_regularizer= tf.keras.regularizers.l2(l= 0.016), activity_regularizer= tf.keras.regularizers.l1(0.006),\n",
    "                bias_regularizer= tf.keras.regularizers.l1(0.006), activation='relu'),\n",
    "    tf.keras.layers.Dropout(.45, seed=42),\n",
    "    tf.keras.layers.Dense(4,activation='softmax')\n",
    "])\n",
    "\n",
    "model = tf.keras.Model(inputs=input, outputs=Output)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "transfer_model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=.001), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fec2227-5582-4f66-9001-379f81e736d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 56s 948ms/step - loss: 4.2211 - accuracy: 0.4090 - val_loss: 4.3892 - val_accuracy: 0.2778\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 17s 521ms/step - loss: 3.3772 - accuracy: 0.4920 - val_loss: 3.4688 - val_accuracy: 0.4444\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 17s 512ms/step - loss: 2.8729 - accuracy: 0.5430 - val_loss: 2.9598 - val_accuracy: 0.3889\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 17s 526ms/step - loss: 2.4497 - accuracy: 0.6150 - val_loss: 2.6956 - val_accuracy: 0.5556\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 16s 506ms/step - loss: 2.1320 - accuracy: 0.6430 - val_loss: 2.5963 - val_accuracy: 0.4444\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 16s 508ms/step - loss: 1.9227 - accuracy: 0.6600 - val_loss: 2.2639 - val_accuracy: 0.5000\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 16s 499ms/step - loss: 1.6982 - accuracy: 0.6750 - val_loss: 2.1146 - val_accuracy: 0.4444\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 17s 510ms/step - loss: 1.5632 - accuracy: 0.6780 - val_loss: 2.0935 - val_accuracy: 0.3889\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 17s 532ms/step - loss: 1.4530 - accuracy: 0.7180 - val_loss: 2.2628 - val_accuracy: 0.3611\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 17s 529ms/step - loss: 1.3201 - accuracy: 0.7370 - val_loss: 2.0996 - val_accuracy: 0.3611\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 17s 532ms/step - loss: 1.2350 - accuracy: 0.7400 - val_loss: 2.0407 - val_accuracy: 0.3333\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 18s 566ms/step - loss: 1.1496 - accuracy: 0.7470 - val_loss: 2.0871 - val_accuracy: 0.5000\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 19s 582ms/step - loss: 1.0783 - accuracy: 0.7790 - val_loss: 2.0947 - val_accuracy: 0.4444\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 19s 583ms/step - loss: 1.0450 - accuracy: 0.7660 - val_loss: 1.7881 - val_accuracy: 0.4167\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 20s 616ms/step - loss: 0.9915 - accuracy: 0.7860 - val_loss: 1.8169 - val_accuracy: 0.4167\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 21s 638ms/step - loss: 0.9098 - accuracy: 0.8040 - val_loss: 1.9823 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 18s 561ms/step - loss: 0.8543 - accuracy: 0.8080 - val_loss: 2.4537 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 19s 593ms/step - loss: 0.8498 - accuracy: 0.8050 - val_loss: 1.9855 - val_accuracy: 0.3333\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 20s 631ms/step - loss: 0.8153 - accuracy: 0.8130 - val_loss: 1.9721 - val_accuracy: 0.5000\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 21s 653ms/step - loss: 0.7823 - accuracy: 0.8210 - val_loss: 1.5720 - val_accuracy: 0.5556\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 24s 750ms/step - loss: 0.7465 - accuracy: 0.8370 - val_loss: 2.1874 - val_accuracy: 0.4722\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 28s 877ms/step - loss: 0.7223 - accuracy: 0.8390 - val_loss: 2.0040 - val_accuracy: 0.4444\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 26s 824ms/step - loss: 0.6794 - accuracy: 0.8480 - val_loss: 1.7029 - val_accuracy: 0.5278\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6789 - accuracy: 0.8470Restoring model weights from the end of the best epoch: 4.\n",
      "32/32 [==============================] - 24s 744ms/step - loss: 0.6789 - accuracy: 0.8470 - val_loss: 1.8695 - val_accuracy: 0.4722\n",
      "Epoch 24: early stopping\n"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, baseline=.1, verbose=1, restore_best_weights=True)\n",
    "#load_model = keras.models.load_model(\"round2-3x3chess_eval.keras\")\n",
    "#load_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=.0005), loss=tf.keras.losses.MeanSquaredError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "history = transfer_model.fit(x=train_generator, epochs=100, shuffle=True, validation_data=(validation_generator), validation_freq=1, callbacks=callback)\n",
    "model.save(\"petemo_model2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8e3f253a-a223-477c-89e5-32e6c1cd0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 135ms/step\n",
      "[[2.4820996e-09 1.7755623e-07 5.9820577e-03 9.9401772e-01]]\n",
      "[3]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_path = 'data/Master Folder/test/Sad/018.jpg'\n",
    "load_model = keras.models.load_model('petemo_model.keras')\n",
    "img = image.load_img(test_path, target_size=(224, 224))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "\n",
    "pred = load_model.predict(images, batch_size=10)\n",
    "print(pred)\n",
    "print(np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4883b559-632d-4950-b87b-5f7fb3de18e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.compat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfjs\u001b[39;00m\n\u001b[0;32m      2\u001b[0m load_model \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpetemo_model.keras\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m tfjs\u001b[38;5;241m.\u001b[39mconverters\u001b[38;5;241m.\u001b[39msave_keras_model(load_model, petemo\u001b[38;5;241m.\u001b[39mjson)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflowjs\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-imports\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m converters\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m version\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflowjs\\converters\\__init__.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-imports,line-too-long\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_h5_conversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_keras_model\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconverters\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras_tfjs_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deserialize_keras_model\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\dl\\lib\\site-packages\\tensorflowjs\\converters\\converter.py:29\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mh5py\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf1\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflowjs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quantization\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.compat'"
     ]
    }
   ],
   "source": [
    "import tensorflowjs as tfjs\n",
    "load_model = keras.models.load_model('petemo_model.keras')\n",
    "tfjs.converters.save_keras_model(load_model, petemo.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecb1dd9-e457-4bfa-97d5-fbee5c9b4930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
